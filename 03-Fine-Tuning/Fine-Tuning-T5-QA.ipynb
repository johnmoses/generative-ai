{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning FLAN T5 for Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"keivalya/MedQuad-MedicalQnADataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['qtype', 'Question', 'Answer'],\n",
       "        num_rows: 16407\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_text_generate_question_answer(data, train_name):\n",
    "    # Extract questions and answers\n",
    "    questions = [entry['Question'] for entry in data]\n",
    "    answers = [entry['Answer'] for entry in data]\n",
    "    qtype = [entry['qtype'] for entry in data]\n",
    "\n",
    "    # Store questions and answers in a text file\n",
    "    with open(train_name, 'w') as text_file:\n",
    "        for q, a, t in zip(questions, answers,qtype):\n",
    "            text_file.write(f\"[Q] {q}\\n[A] {a}\\n[T] {t}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_generate_question_answer(dataset['train'], 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator\n",
    "\n",
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "    data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "        \n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "    trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=train_dataset,\n",
    "    )\n",
    "        \n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = os.path.join(os.getcwd(),\"train.txt\" )\n",
    "model_name = 'gpt2'\n",
    "output_dir = 'output'\n",
    "overwrite_output_dir = False\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 3\n",
    "save_steps = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/huggingface_hub-0.24.0-py3.8.egg/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/accelerate/accelerator.py:451: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnmosesng\u001b[0m (\u001b[33mjohnmosesng-axiis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc8206bb3b24598b9dbd9688fb4df8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011169211577777737, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/johnmoses/Codings/generative-ai-essentials/03-Fine-Tuning/wandb/run-20240904_115647-6c7pgrow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/johnmosesng-axiis/huggingface/runs/6c7pgrow' target=\"_blank\">swift-sound-20</a></strong> to <a href='https://wandb.ai/johnmosesng-axiis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/johnmosesng-axiis/huggingface' target=\"_blank\">https://wandb.ai/johnmosesng-axiis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/johnmosesng-axiis/huggingface/runs/6c7pgrow' target=\"_blank\">https://wandb.ai/johnmosesng-axiis/huggingface/runs/6c7pgrow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290c63fd327345e1828e3d3c0ba7c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1298, 'learning_rate': 4.8430929517353924e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8796, 'learning_rate': 4.686185903470784e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7911, 'learning_rate': 4.529278855206176e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7144, 'learning_rate': 4.3723718069415684e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7018, 'learning_rate': 4.21546475867696e-05, 'epoch': 0.47}\n",
      "{'loss': 1.669, 'learning_rate': 4.058557710412352e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6141, 'learning_rate': 3.9016506621477436e-05, 'epoch': 0.66}\n",
      "{'loss': 1.6205, 'learning_rate': 3.744743613883136e-05, 'epoch': 0.75}\n",
      "{'loss': 1.5766, 'learning_rate': 3.5878365656185273e-05, 'epoch': 0.85}\n",
      "{'loss': 1.5777, 'learning_rate': 3.4309295173539195e-05, 'epoch': 0.94}\n",
      "{'loss': 1.539, 'learning_rate': 3.274022469089312e-05, 'epoch': 1.04}\n",
      "{'loss': 1.4684, 'learning_rate': 3.117115420824704e-05, 'epoch': 1.13}\n",
      "{'loss': 1.4635, 'learning_rate': 2.9602083725600955e-05, 'epoch': 1.22}\n",
      "{'loss': 1.4599, 'learning_rate': 2.8033013242954877e-05, 'epoch': 1.32}\n",
      "{'loss': 1.4484, 'learning_rate': 2.6463942760308795e-05, 'epoch': 1.41}\n",
      "{'loss': 1.4577, 'learning_rate': 2.4894872277662714e-05, 'epoch': 1.51}\n",
      "{'loss': 1.4656, 'learning_rate': 2.3325801795016633e-05, 'epoch': 1.6}\n",
      "{'loss': 1.4487, 'learning_rate': 2.1756731312370555e-05, 'epoch': 1.69}\n",
      "{'loss': 1.4476, 'learning_rate': 2.0187660829724473e-05, 'epoch': 1.79}\n",
      "{'loss': 1.4428, 'learning_rate': 1.8618590347078392e-05, 'epoch': 1.88}\n",
      "{'loss': 1.4326, 'learning_rate': 1.704951986443231e-05, 'epoch': 1.98}\n",
      "{'loss': 1.3883, 'learning_rate': 1.548044938178623e-05, 'epoch': 2.07}\n",
      "{'loss': 1.3653, 'learning_rate': 1.3911378899140151e-05, 'epoch': 2.17}\n",
      "{'loss': 1.3608, 'learning_rate': 1.234230841649407e-05, 'epoch': 2.26}\n",
      "{'loss': 1.3738, 'learning_rate': 1.0773237933847988e-05, 'epoch': 2.35}\n",
      "{'loss': 1.3755, 'learning_rate': 9.204167451201909e-06, 'epoch': 2.45}\n",
      "{'loss': 1.3635, 'learning_rate': 7.635096968555829e-06, 'epoch': 2.54}\n",
      "{'loss': 1.366, 'learning_rate': 6.0660264859097475e-06, 'epoch': 2.64}\n",
      "{'loss': 1.3731, 'learning_rate': 4.496956003263666e-06, 'epoch': 2.73}\n",
      "{'loss': 1.3617, 'learning_rate': 2.927885520617586e-06, 'epoch': 2.82}\n",
      "{'loss': 1.3792, 'learning_rate': 1.3588150379715057e-06, 'epoch': 2.92}\n",
      "{'train_runtime': 12648.6017, 'train_samples_per_second': 10.076, 'train_steps_per_second': 1.26, 'train_loss': 1.5133336974067189, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:02:42.680286, resuming normal operation.\n",
      "wandb: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:02:43.901390, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mforge39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
