{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning T5 for SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 10:28:28.589609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "from transformers import TextDataset, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, concatenate_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Check settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"        \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csql_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:8%]')\n",
    "dataset_csql_test = load_dataset(\"b-mc2/sql-create-context\", split='train[-2%:-1%]')\n",
    "dataset_csql_val = load_dataset(\"b-mc2/sql-create-context\", split='train[-1%:]')\n",
    "\n",
    "dataset_tsql_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:8%]')\n",
    "dataset_tsql_train = dataset_tsql_train.remove_columns(['source', 'text'])\n",
    "dataset_tsql_train = dataset_tsql_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "dataset_tsql_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-2%:-1%]')\n",
    "dataset_tsql_test  = dataset_tsql_test.remove_columns(['source', 'text'])\n",
    "dataset_tsql_test  = dataset_tsql_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "dataset_tsql_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-1%:]')\n",
    "dataset_tsql_val   = dataset_tsql_val.remove_columns(['source', 'text'])\n",
    "dataset_tsql_val   = dataset_tsql_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_train, \n",
    "        # dataset_tsql_train\n",
    "        ]\n",
    "    )\n",
    "dataset_test_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_test, \n",
    "        # dataset_tsql_test\n",
    "        ]\n",
    "    )\n",
    "dataset_val_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_val, \n",
    "        # dataset_tsql_val\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b5b73a82d84de0b6ad5566bbecef36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711f7bae5bb74c9ea1d7408ece6a5e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73506745d21419a82f5effb99ce66d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "168122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_merged.to_csv('train_merged.csv', index=False)\n",
    "dataset_test_merged.to_csv('test_merged.csv', index=False)\n",
    "dataset_val_merged.to_csv('val_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer'],\n",
       "    num_rows: 6286\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer'],\n",
       "    num_rows: 786\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer'],\n",
       "    num_rows: 786\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files={\n",
    "    \"train\": \"train_merged.csv\", \n",
    "    \"test\": \"test_merged.csv\", \n",
    "    \"val\": \"val_merged.csv\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 6286\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 786\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 786\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'CREATE TABLE table_name_41 (entrant VARCHAR, year INTEGER)',\n",
       " 'question': 'Who was the entrant before 1988?',\n",
       " 'answer': 'SELECT entrant FROM table_name_41 WHERE year < 1988'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer\n",
    "Define configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name='google/flan-t5-small'\n",
    "model_name='t5-small'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "base_model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(sample):\n",
    "    start_prompt = \"Tables:\\n\"\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
    "\n",
    "    data_zip = zip(sample['context'], sample['question'])\n",
    "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
    "    sample['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    sample['labels'] = tokenizer(sample['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87761718ca4f42e8a026f9e08bf516ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/786 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['question','context','answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 6286\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 786\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 786\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test', 'val'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'labels'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4398, 7, 10, 205, 4386, 6048, 332, 17098, 819, 41]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 23143, 14196, 2847, 17161, 599, 1935, 61, 21680, 819]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6286, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['val'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model with zero shot prediction/inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Tables:\n",
      "CREATE TABLE table_name_41 (entrant VARCHAR, year INTEGER)\n",
      "\n",
      "Question:\n",
      "Who was the entrant before 1988?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "SELECT entrant FROM table_name_41 WHERE year < 1988\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Question: Who was the entrant before 1988? Answer: Who was the entrant before 1988?\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs = inputs.to('cpu')\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    base_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\")\n",
    "    finetuned_model = finetuned_model.to('cpu')\n",
    "    to_train = False\n",
    "\n",
    "except:\n",
    "    to_train = True\n",
    "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    finetuned_model = finetuned_model.to('cpu')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1540: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a256769247854986be87d28c2eadff67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/786 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.332, 'grad_norm': 0.09357812255620956, 'learning_rate': 0.0046819338422391865, 'epoch': 0.13}\n",
      "{'loss': 0.079, 'grad_norm': 0.08880062401294708, 'learning_rate': 0.004363867684478371, 'epoch': 0.25}\n",
      "{'loss': 0.0532, 'grad_norm': 0.07429048418998718, 'learning_rate': 0.0040458015267175575, 'epoch': 0.38}\n",
      "{'loss': 0.0422, 'grad_norm': 0.06269390881061554, 'learning_rate': 0.003727735368956743, 'epoch': 0.51}\n",
      "{'loss': 0.0361, 'grad_norm': 0.04715965688228607, 'learning_rate': 0.003409669211195929, 'epoch': 0.64}\n",
      "{'loss': 0.0322, 'grad_norm': 0.07090552151203156, 'learning_rate': 0.003091603053435115, 'epoch': 0.76}\n",
      "{'loss': 0.031, 'grad_norm': 0.06011456251144409, 'learning_rate': 0.0027735368956743, 'epoch': 0.89}\n",
      "{'loss': 0.0281, 'grad_norm': 0.03623080998659134, 'learning_rate': 0.002455470737913486, 'epoch': 1.02}\n",
      "{'loss': 0.0232, 'grad_norm': 0.02512708678841591, 'learning_rate': 0.002137404580152672, 'epoch': 1.15}\n",
      "{'loss': 0.0192, 'grad_norm': 0.0392158180475235, 'learning_rate': 0.0018193384223918574, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357fdf4a54e94b258696f09ad4e1eb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0701521635055542, 'eval_runtime': 275.8649, 'eval_samples_per_second': 2.849, 'eval_steps_per_second': 0.181, 'epoch': 1.27}\n",
      "{'loss': 0.0211, 'grad_norm': 0.045559316873550415, 'learning_rate': 0.0015012722646310433, 'epoch': 1.4}\n",
      "{'loss': 0.0203, 'grad_norm': 0.029621044173836708, 'learning_rate': 0.001183206106870229, 'epoch': 1.53}\n",
      "{'loss': 0.0175, 'grad_norm': 0.03458360955119133, 'learning_rate': 0.0008651399491094148, 'epoch': 1.65}\n",
      "{'loss': 0.0166, 'grad_norm': 0.03688393533229828, 'learning_rate': 0.0005470737913486006, 'epoch': 1.78}\n",
      "{'loss': 0.0169, 'grad_norm': 0.0318748913705349, 'learning_rate': 0.00022900763358778625, 'epoch': 1.91}\n",
      "{'train_runtime': 28249.7712, 'train_samples_per_second': 0.445, 'train_steps_per_second': 0.028, 'train_loss': 0.04972395581446835, 'epoch': 2.0}\n",
      "CPU times: user 1d 5h 29min 5s, sys: 15h 4min 48s, total: 1d 20h 33min 53s\n",
      "Wall time: 7h 50min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if to_train:\n",
    "    output_dir = 'training'\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=5e-3,\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=16,     # batch size per device during training\n",
    "        per_device_eval_batch_size=16,      # batch size for evaluation\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        evaluation_strategy='steps',        # evaluation strategy to adopt during training\n",
    "        eval_steps=500,  \n",
    "        no_cuda=True,                 \n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=finetuned_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['val'],\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    finetuned_model.save_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model\"\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test fine-tuned model with zero shot inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Tables:\n",
      "CREATE TABLE table_name_89 (engine VARCHAR, year VARCHAR)\n",
      "\n",
      "Question:\n",
      "Which engine was used in 1987?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "SELECT engine FROM table_name_89 WHERE year = 1987\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "FINE-TUNED MODEL - ZERO SHOT:\n",
      "SELECT engine FROM table_89 WHERE year = 1987\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "# index = len(dataset['test'])-200\n",
    "\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs = inputs.to('cpu')\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    finetuned_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test fine-tuned model with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(query):\n",
    "    prompt = \"translate English to SQL: %s \" % query\n",
    "    features = tokenizer([prompt], return_tensors='pt')\n",
    "    output = finetuned_model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        max_new_tokens=200\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT engine FROM 1987'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which engine was used in 1987?\"\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the division record for the Indians?\n",
      "Predict. :SELECT division_ record FROM Indians\n",
      "Expected: SELECT division_record FROM table_name_26 WHERE team = \"indians\"\n",
      "=================================\n",
      "\n",
      "Question: What is the overall record of Indian River?\n",
      "Predict. :SELECT overall_registration FROM Indian River\n",
      "Expected: SELECT overall_record FROM table_name_17 WHERE school = \"indian river\"\n",
      "=================================\n",
      "\n",
      "Question: What was the season outcome of Lake Forest?\n",
      "Predict. :SELECT season FROM Lake Forest\n",
      "Expected: SELECT season_outcome FROM table_name_43 WHERE school = \"lake forest\"\n",
      "=================================\n",
      "\n",
      "Question: How many Deciles are coed?\n",
      "Predict. :SELECT CODEDEDELES COUNT(*) FROM Deciles\n",
      "Expected: SELECT COUNT(decile) FROM table_name_51 WHERE gender = \"coed\"\n",
      "=================================\n",
      "\n",
      "Question: Which is the lowest Decile that is coed?\n",
      "Predict. :SELECT MIN(Decle) FROM coed\n",
      "Expected: SELECT MIN(decile) FROM table_name_94 WHERE gender = \"coed\"\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15, 1):\n",
    "    print('Question: ' + dataset['test'][i]['question'])\n",
    "    print('Predict. :' + get_sql(dataset['test'][i]['question']))\n",
    "    print('Expected: ' + dataset['test'][i]['answer'])\n",
    "    print('=================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = dataset['test'][0:10]['question']\n",
    "answer = dataset['test'][0:10]['answer']\n",
    "\n",
    "base_model_answers = []\n",
    "finetuned_model_answers = []\n",
    "\n",
    "for question in questions:\n",
    "    prompt = f\"\"\" \n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    finetuned_model_outputs = finetuned_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    finetuned_model_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    base_model_outputs = base_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    base_model_output = tokenizer.decode(base_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    finetuned_model_answers.append(finetuned_model_output)\n",
    "    base_model_answers.append(base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT entrant FROM table_name_41 WHERE year &lt;...</td>\n",
       "      <td>entrant entrant enrant enrant enrant enrant en...</td>\n",
       "      <td>Question: Who was the entrant before 1988? Ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT engine FROM table_name_89 WHERE year = ...</td>\n",
       "      <td>SELECT engine__191987</td>\n",
       "      <td>Question: Which engine was used in 1987? Answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT league FROM table_name_39 WHERE year = ...</td>\n",
       "      <td>SELECT league FROM league WATCHE19 2001</td>\n",
       "      <td>Question: What league did they play in 2001? A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT open_cup FROM table_name_21 WHERE reg_s...</td>\n",
       "      <td>SELECT open cup FROM cup WHERE open cup = 2nd,...</td>\n",
       "      <td>Question: What open cup did they play in when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT COUNT(week) FROM table_name_27 WHERE da...</td>\n",
       "      <td>SELECT week FROM date of October 9, 1983, atte...</td>\n",
       "      <td>Question: What is the week with a date of Octo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SELECT MIN(attendance) FROM table_name_30 WHER...</td>\n",
       "      <td>SELECT MIN(attendance) FROM week 14</td>\n",
       "      <td>Answer: What is the lowest attendance with wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SELECT game_site FROM table_name_90 WHERE week...</td>\n",
       "      <td>SELECT Oakland Raiders, Oakland Raiders, Oakla...</td>\n",
       "      <td>Answer:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SELECT SUM(year) FROM table_name_43 WHERE entr...</td>\n",
       "      <td>SELECT COUNT(1986 years) FROM Cosworth v8 engine</td>\n",
       "      <td>Answer: How many years did Barclay Nordica Arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SELECT SUM(year) FROM table_name_98 WHERE engi...</td>\n",
       "      <td>SELECT COUNT(19 years) FROM bmw WHERE bmw str-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT SUM(year) FROM table_name_12 WHERE poin...</td>\n",
       "      <td>ensign n180b a Chassis with 4 points</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               human  \\\n",
       "0  SELECT entrant FROM table_name_41 WHERE year <...   \n",
       "1  SELECT engine FROM table_name_89 WHERE year = ...   \n",
       "2  SELECT league FROM table_name_39 WHERE year = ...   \n",
       "3  SELECT open_cup FROM table_name_21 WHERE reg_s...   \n",
       "4  SELECT COUNT(week) FROM table_name_27 WHERE da...   \n",
       "5  SELECT MIN(attendance) FROM table_name_30 WHER...   \n",
       "6  SELECT game_site FROM table_name_90 WHERE week...   \n",
       "7  SELECT SUM(year) FROM table_name_43 WHERE entr...   \n",
       "8  SELECT SUM(year) FROM table_name_98 WHERE engi...   \n",
       "9  SELECT SUM(year) FROM table_name_12 WHERE poin...   \n",
       "\n",
       "                                           finetuned  \\\n",
       "0  entrant entrant enrant enrant enrant enrant en...   \n",
       "1                              SELECT engine__191987   \n",
       "2            SELECT league FROM league WATCHE19 2001   \n",
       "3  SELECT open cup FROM cup WHERE open cup = 2nd,...   \n",
       "4  SELECT week FROM date of October 9, 1983, atte...   \n",
       "5                SELECT MIN(attendance) FROM week 14   \n",
       "6  SELECT Oakland Raiders, Oakland Raiders, Oakla...   \n",
       "7   SELECT COUNT(1986 years) FROM Cosworth v8 engine   \n",
       "8  SELECT COUNT(19 years) FROM bmw WHERE bmw str-...   \n",
       "9               ensign n180b a Chassis with 4 points   \n",
       "\n",
       "                                                base  \n",
       "0  Question: Who was the entrant before 1988? Ans...  \n",
       "1  Question: Which engine was used in 1987? Answe...  \n",
       "2  Question: What league did they play in 2001? A...  \n",
       "3  Question: What open cup did they play in when ...  \n",
       "4  Question: What is the week with a date of Octo...  \n",
       "5  Answer: What is the lowest attendance with wee...  \n",
       "6                                            Answer:  \n",
       "7  Answer: How many years did Barclay Nordica Arr...  \n",
       "8                                               True  \n",
       "9                                               True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_answers = list(zip(answer, finetuned_model_answers, base_model_answers))\n",
    "df = pd.DataFrame(zipped_answers, columns=['human','finetuned','base'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = dataset['test'][0:10]['answer']\n",
    "\n",
    "finetuned_model_results = rouge.compute(\n",
    "    predictions=finetuned_model_answers,\n",
    "    references=answer,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=base_model_answers,\n",
    "    references=answer,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned\n",
      " {'rouge1': 0.47508313963883425, 'rouge2': 0.2219484050147666, 'rougeL': 0.42335379541887685, 'rougeLsum': 0.42434819317798045}\n",
      "Base\n",
      " {'rouge1': 0.19241943734015343, 'rouge2': 0.07258823529411765, 'rougeL': 0.17581084825234441, 'rougeLsum': 0.17674381926683713}\n"
     ]
    }
   ],
   "source": [
    "print('Fine-tuned\\n',finetuned_model_results)\n",
    "print('Base\\n',base_model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mconda38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
