{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning T5 for Customer Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 05:09:11.215096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration, GenerationConfig, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='t5-small'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "base_model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since bitext/Bitext-customer-support-llm-chatbot-training-dataset couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/johnmoses/.cache/huggingface/datasets/bitext___bitext-customer-support-llm-chatbot-training-dataset/default/0.0.0/430d1a89bd93bd1fa23c16f29dd53e73f0087443 (last modified on Thu Sep  5 17:13:46 2024).\n",
      "Using the latest cached version of the dataset since bitext/Bitext-customer-support-llm-chatbot-training-dataset couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/johnmoses/.cache/huggingface/datasets/bitext___bitext-customer-support-llm-chatbot-training-dataset/default/0.0.0/430d1a89bd93bd1fa23c16f29dd53e73f0087443 (last modified on Thu Sep  5 17:13:46 2024).\n",
      "Using the latest cached version of the dataset since bitext/Bitext-customer-support-llm-chatbot-training-dataset couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/johnmoses/.cache/huggingface/datasets/bitext___bitext-customer-support-llm-chatbot-training-dataset/default/0.0.0/430d1a89bd93bd1fa23c16f29dd53e73f0087443 (last modified on Thu Sep  5 17:13:46 2024).\n"
     ]
    }
   ],
   "source": [
    "dataset_bitext_train = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\", split=\"train[:24000]\")\n",
    "dataset_bitext_test = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\", split=\"train[-6000:-3000]\")\n",
    "dataset_bitext_validation = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\", split=\"train[-3000:]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_merged = concatenate_datasets(\n",
    "    [dataset_bitext_train]\n",
    ")\n",
    "dataset_test_merged = concatenate_datasets(\n",
    "    [dataset_bitext_test]\n",
    ")\n",
    "dataset_validation_merged = concatenate_datasets(\n",
    "    [dataset_bitext_validation]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save datasets locally as `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b155f86bba34987965ab38fc0f75105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe507ee9402142afbcebf01790d35053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b974acbb54f64824b4d4c3e5fbc12998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2111954"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_merged.to_csv('train_merged.csv', index=False)\n",
    "dataset_test_merged.to_csv('test_merged.csv', index=False)\n",
    "dataset_validation_merged.to_csv('validation_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "    num_rows: 24000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_validation_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load merged dataset from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907979a3d4df4e779ff2c0c7d1cae546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865fad495eb8479ba55f9b4dea002b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d548eb7c22402dbbca83b8e398771e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={\n",
    "    \"train\": \"train_merged.csv\", \n",
    "    \"test\": \"test_merged.csv\", \n",
    "    \"validation\": \"validation_merged.csv\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flags': 'B',\n",
       " 'instruction': 'question about cancelling order {{Order Number}}',\n",
       " 'category': 'ORDER',\n",
       " 'intent': 'cancel_order',\n",
       " 'response': \"I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('./train_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flags                                        instruction category  \\\n",
       "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "\n",
       "         intent                                           response  \n",
       "0  cancel_order  I've understood you have a question regarding ...  \n",
       "1  cancel_order  I've been informed that you have a question ab...  \n",
       "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3  cancel_order  I understood that you need assistance with can...  \n",
       "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, eos_token=\"<|im_end|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to translate English to German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "<pad> Wie alt sind Sie?</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = base_model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get instruction prompt using an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(data, index):\n",
    "    instruction = data.iloc[index]['instruction']\n",
    "    response = data.iloc[index]['response']\n",
    "    \n",
    "    prompt = f'''\n",
    "    instruction:\n",
    "    {instruction}\n",
    "    \n",
    "    response:\n",
    "    {response}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def get_instruction(data,index):\n",
    "    instruction = data.iloc[index]['instruction']\n",
    "    return f'''\n",
    "    \n",
    "    instruction:\n",
    "    {instruction}\n",
    "    \n",
    "    response:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model output with one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    instruction:\n",
      "    question about cancelling order {{Order Number}}\n",
      "    \n",
      "    response:\n",
      "    I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\n",
      "    \n",
      "    \n",
      "    \n",
      "    instruction:\n",
      "    i dont know what to do to cancel order {{Order Number}}\n",
      "    \n",
      "    response:\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "test_prompt = get_prompt(dataset_train,0) + get_instruction(dataset_train,10)\n",
    "print(test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad><extra_id_0>: I have understood you have a question regarding cancelling order <unk>Order Number\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.encode(test_prompt,return_tensors=\"pt\")\n",
    "output = tokenizer.decode(base_model.generate(input_text)[0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction:\n",
      "canceling order {{Order Number}}\n",
      "\n",
      "response:\n",
      "\n",
      "======================\n",
      "expected reponse: \n",
      " I appreciate that you're seeking assistance with canceling your order tied to the order number {{Order Number}}, and I'm here to guide you through the cancellation process. Please follow these steps:\n",
      "\n",
      "1. Access Your Account: Log in to your {{Online Company Portal Info}} using your username and password.\n",
      "2. Navigate to Your Orders: Once you're logged in, locate the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
      "3. Locate the Order: Look for the specific order associated with the order number {{Order Number}}.\n",
      "4. Initiate the Cancellation: Within the order details, you should find an option to '{{Online Order Interaction}}'. Click on it to start the cancellation process.\n",
      "5. Confirm the Cancellation: The system may ask for your confirmation or gather feedback. Please provide the necessary information accurately.\n",
      "\n",
      "If you encounter any difficulties or have further questions, our dedicated customer support team is available during {{Customer Support Hours}}. You can reach us at {{Customer Support Phone Number}} or through the Live Chat feature on our {{Website URL}}. We value your satisfaction and are committed to assisting you through this process.\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "idx_var = 50\n",
    "\n",
    "check = dataset_train.iloc[idx]['instruction']\n",
    "check2 = dataset_train.iloc[idx]['response']\n",
    "\n",
    "test = dataset_train.iloc[idx_var]['instruction']\n",
    "test_response = dataset_train.iloc[idx_var]['response']\n",
    "\n",
    "print(f'instruction:\\n{test}\\n\\nresponse:\\n')\n",
    "\n",
    "print(f'======================\\nexpected reponse: \\n {test_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Instruction:\\n'\n",
    "    end_prompt = '\\nResponse:'\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"instruction\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"response\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63a2b77a79146cda38200bc47076c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d6029a65948e390d96df2c5fddd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d1148ebca24ed29afc7cbe3858da6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = shuffled_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['flags', 'instruction', 'category', 'intent', 'response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "finetuned_model = finetuned_model.to('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = 't5-customer-service-log'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-3,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,     # batch size per device during training\n",
    "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='steps',        # evaluation strategy to adopt during training\n",
    "    eval_steps=500,                 \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15fc5515fd042898c3f81c5d7b49cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.600660800933838,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_runtime': 115.4695,\n",
       " 'eval_samples_per_second': 25.981,\n",
       " 'eval_steps_per_second': 1.628}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0952cedac298412e9b52abd92f4bfc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1855, 'grad_norm': 0.16349054872989655, 'learning_rate': 0.004916666666666666, 'epoch': 0.03}\n",
      "{'loss': 0.4826, 'grad_norm': 0.10131632536649704, 'learning_rate': 0.004833333333333334, 'epoch': 0.07}\n",
      "{'loss': 0.4295, 'grad_norm': 0.12298038601875305, 'learning_rate': 0.00475, 'epoch': 0.1}\n",
      "{'loss': 0.4072, 'grad_norm': 0.09317249804735184, 'learning_rate': 0.004666666666666667, 'epoch': 0.13}\n",
      "{'loss': 0.3787, 'grad_norm': 0.12126368284225464, 'learning_rate': 0.004583333333333333, 'epoch': 0.17}\n",
      "{'loss': 0.3543, 'grad_norm': 0.07475490868091583, 'learning_rate': 0.0045000000000000005, 'epoch': 0.2}\n",
      "{'loss': 0.3445, 'grad_norm': 0.0923856794834137, 'learning_rate': 0.004416666666666667, 'epoch': 0.23}\n",
      "{'loss': 0.3475, 'grad_norm': 0.09289425611495972, 'learning_rate': 0.004333333333333334, 'epoch': 0.27}\n",
      "{'loss': 0.3121, 'grad_norm': 0.10281085222959518, 'learning_rate': 0.00425, 'epoch': 0.3}\n",
      "{'loss': 0.3135, 'grad_norm': 0.10240963846445084, 'learning_rate': 0.004166666666666667, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be8db80fa524234bca89c0c2a501117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39064279198646545, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 115.088, 'eval_samples_per_second': 26.067, 'eval_steps_per_second': 1.634, 'epoch': 0.33}\n",
      "{'loss': 0.3198, 'grad_norm': 0.086480051279068, 'learning_rate': 0.004083333333333333, 'epoch': 0.37}\n",
      "{'loss': 0.3155, 'grad_norm': 0.11693891882896423, 'learning_rate': 0.004, 'epoch': 0.4}\n",
      "{'loss': 0.2991, 'grad_norm': 0.08312585949897766, 'learning_rate': 0.003916666666666666, 'epoch': 0.43}\n",
      "{'loss': 0.2983, 'grad_norm': 0.08346576243638992, 'learning_rate': 0.0038333333333333336, 'epoch': 0.47}\n",
      "{'loss': 0.2991, 'grad_norm': 0.08641285449266434, 'learning_rate': 0.00375, 'epoch': 0.5}\n",
      "{'loss': 0.2799, 'grad_norm': 0.07280765473842621, 'learning_rate': 0.0036666666666666666, 'epoch': 0.53}\n",
      "{'loss': 0.2873, 'grad_norm': 0.08434479683637619, 'learning_rate': 0.0035833333333333333, 'epoch': 0.57}\n",
      "{'loss': 0.2637, 'grad_norm': 0.0968218743801117, 'learning_rate': 0.0034999999999999996, 'epoch': 0.6}\n",
      "{'loss': 0.2904, 'grad_norm': 0.09086223691701889, 'learning_rate': 0.003416666666666667, 'epoch': 0.63}\n",
      "{'loss': 0.2785, 'grad_norm': 0.11159786581993103, 'learning_rate': 0.003333333333333333, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8fc43561d54427a8b421e1151ef67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3504338264465332, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 115.3027, 'eval_samples_per_second': 26.018, 'eval_steps_per_second': 1.63, 'epoch': 0.67}\n",
      "{'loss': 0.2739, 'grad_norm': 0.07136990875005722, 'learning_rate': 0.0032500000000000003, 'epoch': 0.7}\n",
      "{'loss': 0.2634, 'grad_norm': 0.08812236785888672, 'learning_rate': 0.0031666666666666666, 'epoch': 0.73}\n",
      "{'loss': 0.2773, 'grad_norm': 0.07205134630203247, 'learning_rate': 0.0030833333333333338, 'epoch': 0.77}\n",
      "{'loss': 0.2707, 'grad_norm': 0.10232723504304886, 'learning_rate': 0.003, 'epoch': 0.8}\n",
      "{'loss': 0.267, 'grad_norm': 0.1256856620311737, 'learning_rate': 0.002916666666666667, 'epoch': 0.83}\n",
      "{'loss': 0.2534, 'grad_norm': 0.08231396228075027, 'learning_rate': 0.002833333333333333, 'epoch': 0.87}\n",
      "{'loss': 0.2552, 'grad_norm': 0.08286572247743607, 'learning_rate': 0.0027500000000000003, 'epoch': 0.9}\n",
      "{'loss': 0.2465, 'grad_norm': 0.07884944975376129, 'learning_rate': 0.0026666666666666666, 'epoch': 0.93}\n",
      "{'loss': 0.2447, 'grad_norm': 0.0851874053478241, 'learning_rate': 0.0025833333333333337, 'epoch': 0.97}\n",
      "{'loss': 0.2541, 'grad_norm': 0.07073597609996796, 'learning_rate': 0.0025, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e656060e60a4252b562277d5edea47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3383970856666565, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 115.1768, 'eval_samples_per_second': 26.047, 'eval_steps_per_second': 1.632, 'epoch': 1.0}\n",
      "{'loss': 0.2396, 'grad_norm': 0.08535576611757278, 'learning_rate': 0.002416666666666667, 'epoch': 1.03}\n",
      "{'loss': 0.239, 'grad_norm': 0.09501548856496811, 'learning_rate': 0.0023333333333333335, 'epoch': 1.07}\n",
      "{'loss': 0.2372, 'grad_norm': 0.08231311291456223, 'learning_rate': 0.0022500000000000003, 'epoch': 1.1}\n",
      "{'loss': 0.2304, 'grad_norm': 0.09446293860673904, 'learning_rate': 0.002166666666666667, 'epoch': 1.13}\n",
      "{'loss': 0.2305, 'grad_norm': 0.08350082486867905, 'learning_rate': 0.0020833333333333333, 'epoch': 1.17}\n",
      "{'loss': 0.2316, 'grad_norm': 0.07536861300468445, 'learning_rate': 0.002, 'epoch': 1.2}\n",
      "{'loss': 0.2265, 'grad_norm': 0.07932144403457642, 'learning_rate': 0.0019166666666666668, 'epoch': 1.23}\n",
      "{'loss': 0.2301, 'grad_norm': 0.08745494484901428, 'learning_rate': 0.0018333333333333333, 'epoch': 1.27}\n",
      "{'loss': 0.2349, 'grad_norm': 0.08737260848283768, 'learning_rate': 0.0017499999999999998, 'epoch': 1.3}\n",
      "{'loss': 0.2229, 'grad_norm': 0.09626562148332596, 'learning_rate': 0.0016666666666666666, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e798c9c039a4416ca7a1731d83910d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3190086781978607, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 114.7595, 'eval_samples_per_second': 26.142, 'eval_steps_per_second': 1.638, 'epoch': 1.33}\n",
      "{'loss': 0.2293, 'grad_norm': 0.08036044239997864, 'learning_rate': 0.0015833333333333333, 'epoch': 1.37}\n",
      "{'loss': 0.2469, 'grad_norm': 0.0995529517531395, 'learning_rate': 0.0015, 'epoch': 1.4}\n",
      "{'loss': 0.2218, 'grad_norm': 0.07272803038358688, 'learning_rate': 0.0014166666666666666, 'epoch': 1.43}\n",
      "{'loss': 0.2295, 'grad_norm': 0.11881940066814423, 'learning_rate': 0.0013333333333333333, 'epoch': 1.47}\n",
      "{'loss': 0.2238, 'grad_norm': 0.0738658756017685, 'learning_rate': 0.00125, 'epoch': 1.5}\n",
      "{'loss': 0.2229, 'grad_norm': 0.07764305174350739, 'learning_rate': 0.0011666666666666668, 'epoch': 1.53}\n",
      "{'loss': 0.2287, 'grad_norm': 0.06067624315619469, 'learning_rate': 0.0010833333333333335, 'epoch': 1.57}\n",
      "{'loss': 0.2252, 'grad_norm': 0.0740363746881485, 'learning_rate': 0.001, 'epoch': 1.6}\n",
      "{'loss': 0.2276, 'grad_norm': 0.08086449652910233, 'learning_rate': 0.0009166666666666666, 'epoch': 1.63}\n",
      "{'loss': 0.2285, 'grad_norm': 0.08366335183382034, 'learning_rate': 0.0008333333333333333, 'epoch': 1.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d9de6971d642bc8b619caec7fcd363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3091459274291992, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 115.4163, 'eval_samples_per_second': 25.993, 'eval_steps_per_second': 1.629, 'epoch': 1.67}\n",
      "{'loss': 0.2207, 'grad_norm': 0.07797810435295105, 'learning_rate': 0.00075, 'epoch': 1.7}\n",
      "{'loss': 0.2211, 'grad_norm': 0.08147252351045609, 'learning_rate': 0.0006666666666666666, 'epoch': 1.73}\n",
      "{'loss': 0.2204, 'grad_norm': 0.07256118953227997, 'learning_rate': 0.0005833333333333334, 'epoch': 1.77}\n",
      "{'loss': 0.2175, 'grad_norm': 0.0893479660153389, 'learning_rate': 0.0005, 'epoch': 1.8}\n",
      "{'loss': 0.2285, 'grad_norm': 0.08022065460681915, 'learning_rate': 0.00041666666666666664, 'epoch': 1.83}\n",
      "{'loss': 0.2184, 'grad_norm': 0.06792289763689041, 'learning_rate': 0.0003333333333333333, 'epoch': 1.87}\n",
      "{'loss': 0.2176, 'grad_norm': 0.06807844340801239, 'learning_rate': 0.00025, 'epoch': 1.9}\n",
      "{'loss': 0.2203, 'grad_norm': 0.07047216594219208, 'learning_rate': 0.00016666666666666666, 'epoch': 1.93}\n",
      "{'loss': 0.2161, 'grad_norm': 0.07137240469455719, 'learning_rate': 8.333333333333333e-05, 'epoch': 1.97}\n",
      "{'loss': 0.2166, 'grad_norm': 0.0710221379995346, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cb216871444648b7b27842b713a8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3029376268386841, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 115.2077, 'eval_samples_per_second': 26.04, 'eval_steps_per_second': 1.632, 'epoch': 2.0}\n",
      "{'train_runtime': 14236.9553, 'train_samples_per_second': 3.372, 'train_steps_per_second': 0.211, 'train_loss': 0.2816208273569743, 'epoch': 2.0}\n",
      "CPU times: user 32min 27s, sys: 13min 41s, total: 46min 9s\n",
      "Wall time: 3h 57min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.2816208273569743, metrics={'train_runtime': 14236.9553, 'train_samples_per_second': 3.372, 'train_steps_per_second': 0.211, 'total_flos': 6496406470656000.0, 'train_loss': 0.2816208273569743, 'epoch': 2.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.save_pretrained(\"t5-customer-service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5-customer-service/tokenizer_config.json',\n",
       " 't5-customer-service/special_tokens_map.json',\n",
       " 't5-customer-service/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"t5-customer-service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"t5-customer-service\"\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "finetuned_model = finetuned_model.to('cpu')\n",
    "\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've realized that you're seeking assistance with canceling order Order Number, and I'm here to help you with that. I apologize for any inconvenience this may have caused you. To cancel your order, please follow these steps: 1. Sign into Your Account: Access our Online Company Portal Info and sign in with your order number Order Number. 2. Access Your Order: Once logged in, navigate to the 'Online Order Interaction' or 'Online Order Interaction' section. 3. Identify the Order: Look for the order with the order number Order Number and click on it. 4. Initiate the Cancellation: You should find the option labeled 'Online Order Interaction' associated with the order Order Number. Click on it to proceed with the cancellation. Please select this option. 5. Follow Any Additional Steps:\n"
     ]
    }
   ],
   "source": [
    "test_prompt = f'instruction:\\n{test}\\n\\nresponse:\\n'\n",
    "input_text = finetuned_tokenizer(test_prompt,return_tensors=\"pt\").input_ids\n",
    "output = finetuned_model.generate(\n",
    "    input_ids=input_text, \n",
    "    generation_config=GenerationConfig(max_new_tokens=200, \n",
    "    num_beams=1))\n",
    "\n",
    "model_text_output = finetuned_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(model_text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question):\n",
    "    test_prompt = f'instruction:\\n{question}\\n\\nresponse:\\n'\n",
    "    input_text = finetuned_tokenizer(test_prompt,return_tensors=\"pt\").input_ids\n",
    "    output = finetuned_model.generate(\n",
    "        input_ids=input_text, \n",
    "        generation_config=GenerationConfig(max_new_tokens=200, \n",
    "        num_beams=1))\n",
    "    return finetuned_tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've got that you have a question regarding canceling order Order Number. I'm here to assist you with that. Please ask me a question, and I'll provide you with the information you need.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"i have a question about cancelling order {{Order Number}}\"\n",
    "get_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: how to recover my bloody access key?\n",
      "Predict. :I'm on the same page, your frustration and urgency in recovering your access key. Let's get you back on track: 1. To initiate the recovery process, please follow these steps: 1. Visit the \"Login Page URL\" of our platform. 2. Look for the \"Forgot Access Key\" option and click on it. 3. You will be prompted to enter the email address associated with your account. Follow the instructions provided to reset your access key. Remember to remember to remember to a key reset key, and a key reset key will be a key back. Follow the instructions provided to regain access to your account. If you encounter any difficulties during the process or if you don't receive the email within a reasonable time, please don't hesitate to reach out to me. I'm here to support you every step of the way.\n",
      "Expected: Absolutely! I understand the importance of recovering your access key and I'm here to assist you every step of the way. Please follow these instructions to regain access to your account:\n",
      "\n",
      "1. Begin by visiting our platform's login page.\n",
      "2. Look for the \"Forgot Access Key\" option and click on it.\n",
      "3. You will be prompted to provide the email address associated with your account.\n",
      "4. After submitting your email address, check your inbox for further instructions. If you don't find the email in your main inbox, make sure to check your spam or junk folders.\n",
      "5. Follow the instructions provided in the email to recover your access key.\n",
      "\n",
      "If you encounter any difficulties or have any questions during the process, feel free to reach out to me. I'm here to support you and ensure a successful recovery of your access key.\n",
      "=================================\n",
      "\n",
      "Instruction: where can I restore the PIN code of my user account?\n",
      "Predict. :I'm on the same page, your need to restore the PIN code for your user account. Let's get started: 1. To initiate the PIN code restoration process, please follow these steps: 1. Go to the \"Login Page URL\" of our platform. 2. Look for the \"Forgot PIN\" option and click on it. 3. You will be prompted to enter the PIN code code of your user account. Follow the instructions provided on the PIN code reset page. 4. You may be prompted to enter the PIN code reset pin code for your user account. Follow the instructions provided on the PIN code reset page to reset your PIN code. Remember, if you encounter any difficulties or have any further questions, don't hesitate to reach out to me. I'm here to support you every step of the way!\n",
      "Expected: Assuredly! I understand that you are looking for a way to restore the PIN code for your user account. Rest assured, I'm here to guide you:\n",
      "\n",
      "To restore the PIN code of your user account, please follow these simple steps:\n",
      "1. Log in to your user account on our platform using your credentials.\n",
      "2. Once you are logged in, navigate to the \"Profile\" or \"Account Settings\" section of your user account.\n",
      "3. Look for the \"Security\" or \"Privacy\" settings within the profile/account settings page.\n",
      "4. In the security/privacy settings, you should find an option to restore or reset your PIN code. Click on that option.\n",
      "5. Follow the instructions provided on the screen to complete the PIN code restoration process.\n",
      "\n",
      "If you encounter any difficulties or if the option is not available in the settings, please don't hesitate to reach out to our customer support team. They will be more than happy to assist you further and ensure that you regain access to your user account.\n",
      "\n",
      "Remember, we are always here to support you throughout this process. Feel free to ask any questions or seek clarification along the way. You've got this!\n",
      "=================================\n",
      "\n",
      "Instruction: I have got to recover my user pwd\n",
      "Predict. :I'll get right on it! I'm here to assist you in recovering your user password. Let's get back on track: 1. To initiate the password recovery process, please follow the steps outlined in the email: 1. Start by visiting the \"Login Page URL\" of our platform. 2. Look for the \"Forgot Password\" option and click on it. 3. You will be prompted to enter the email address associated with your user account. Please follow the instructions provided to reset your password. Please follow the instructions provided to regain access to your user account. Remember to remember to remember to remember to remember to remember your password reset reset reset reset reset reset password. Please remember to remember to remember to a password reset reset reset reset reset reset reset password. Follow the instructions provided in the email to reset your password and regain access to your user account. If you encounter any difficulties during the password recovery process, please don't hesitate to\n",
      "Expected: Unquestionably! I understand the urgency of recovering your user password. Losing access to your account can be frustrating, but worry not, we're here to assist you every step of the way. To initiate the password recovery process:\n",
      "\n",
      "1. Visit our platform's \"{{Login Page URL}}\" and click on the \"{{Forgot Password}}\" option.\n",
      "2. When prompted, enter the email address associated with your user account. Remember to double-check for any spelling errors.\n",
      "3. Sit tight and keep an eye on your inbox! You should receive an email shortly with detailed instructions on how to reset your password. In case you don't see the email in your primary inbox, be sure to look in your spam or junk folder as well.\n",
      "4. Follow the steps provided in the email carefully to reset your user password and gain access to your account once again.\n",
      "\n",
      "If you encounter any obstacles along the way or if the recovery email doesn't arrive within a reasonable timeframe, please don't hesitate to reach out. We're committed to resolving this issue promptly and getting you back into your account. Remember, you're not alone in this process, and we're here to provide the necessary guidance. Stay positive and let's reclaim your account together!\n",
      "=================================\n",
      "\n",
      "Instruction: what do I need ot do to reset my user PIN?\n",
      "Predict. :I've realized that you're seeking guidance on how to reset your user PIN. Let's follow this steps: 1. Begin by logging into your user account using your username and password. 2. Once you're logged in, navigate to the \"Forgot PIN\" option and follow the steps outlined in the email. Follow the instructions provided to reset your PIN: 1. To reset your user PIN, follow the steps outlined in the email carefully. Follow the instructions provided to reset your PIN. Once you've successfully reset your user PIN, you will be prompted to reset your PIN reset PIN. Follow the instructions provided on the PIN reset reset page to a new PIN reset PIN reset reset reset reset key. Remember to a PIN reset reset reset reset reset reset reset reset reset reset: Follow the instructions provided on the PIN reset reset reset reset reset reset reset reset reset reset reset reset reset\n",
      "Expected: Sure! I'm here to assist you with resetting your user PIN. Let's go through the steps together:\n",
      "\n",
      "1. Begin by visiting the \"{{Settings}}\" section of your user profile.\n",
      "2. Look for the \"{{Security}}\" tab or option within the settings menu.\n",
      "3. Once there, you should see the \"Reset PIN\" or a similar option.\n",
      "4. Click on it and follow the prompts to initiate the process of resetting your PIN.\n",
      "5. You might be asked to provide some additional verification information to ensure the security of your account.\n",
      "6. After completing the necessary steps, you'll have the option to set a new PIN for your user profile.\n",
      "\n",
      "If you face any difficulties during this process or have any further questions, please don't hesitate to reach out. I'm here to support you every step of the way!\"\n",
      "=================================\n",
      "\n",
      "Instruction: how do i retrieve my profile pin\n",
      "Predict. :I'm on the same page, your concern about retrieving your profile PIN. Let me guide you through the process: 1. To retrieve your profile PIN, please follow these steps: 1. Go to the \"Login Page URL\" of our platform. 2. Look for the \"Forgot PIN\" option and click on it. 3. You may be prompted to enter the PIN reset link or follow the instructions provided to reset your PIN. Follow the steps outlined in the email to regain access to your profile. Remember, if you encounter any difficulties or if you need further assistance, don't hesitate to reach out to me. I'm here to support you every step of the way.\n",
      "Expected: I'm on it! I'm here to guide you through the process of retrieving your profile PIN. 🌟\n",
      "\n",
      "To regain access to your profile PIN, follow these steps:\n",
      "\n",
      "1. Begin by accessing our platform's login page.\n",
      "2. Look for the option labeled \"Forgot PIN\" and click on it.\n",
      "3. You may be asked to provide some identification information to verify your account. This could include your email address or any alternative contact details associated with your profile.\n",
      "4. Once you've successfully completed the identity verification process, you'll receive further instructions on how to retrieve your profile PIN.\n",
      "5. Be sure to carefully follow the guidelines provided to securely reset your PIN.\n",
      "\n",
      "Remember, I'm here for you at every stage of this journey. If you encounter any challenges or have any additional questions, please don't hesitate to reach out. Your satisfaction and security are our top priorities.\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5, 1):\n",
    "    print('Instruction: ' + dataset['test'][i]['instruction'])\n",
    "    print('Predict. :' + get_response(dataset['test'][i]['instruction']))\n",
    "    print('Expected: ' + dataset['test'][i]['response'])\n",
    "    print('=================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,538,944 || all params: 251,116,800 || trainable%: 1.4093\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(base_model, lora_config)\n",
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/transformers/training_args.py:1332: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/accelerate/accelerator.py:457: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "output_dir = 'training-peft'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs= 3, \n",
    "    no_cuda=True,  \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset= tokenized_datasets['train'],\n",
    "    eval_dataset= tokenized_datasets['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_model, save_model\n",
    "\n",
    "peft_trainer.train()\n",
    "save_model(peft_model, \"model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = dataset['test'][0:25]['instruction']\n",
    "responses = dataset['test'][0:25]['response']\n",
    "\n",
    "base_model_responses = []\n",
    "finetuned_model_responses = []\n",
    "peft_model_responses = []\n",
    "\n",
    "for instruction in instructions:\n",
    "    prompt = f\"\"\" \n",
    "    instruction:\n",
    "    {instruction}\n",
    "\n",
    "    response:\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    base_model_outputs = base_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    base_model_output = tokenizer.decode(base_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    finetuned_model_outputs = finetuned_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    finetuned_model_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    # peft_model_outputs = peft_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    # peft_model_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    base_model_responses.append(base_model_output)\n",
    "    finetuned_model_responses.append(finetuned_model_output)\n",
    "    # peft_model_responses.append(peft_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>base</th>\n",
       "      <th>finetuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely! I understand the importance of rec...</td>\n",
       "      <td>:</td>\n",
       "      <td>I'm on the same page, your frustration and urg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assuredly! I understand that you are looking f...</td>\n",
       "      <td>:</td>\n",
       "      <td>I'm on the same page, your need to restore the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unquestionably! I understand the urgency of re...</td>\n",
       "      <td>I have got to recover my user pwd response:</td>\n",
       "      <td>I'll get right on it! I'm here to assist you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sure! I'm here to assist you with resetting yo...</td>\n",
       "      <td>instruction: what do do ot do to reset my user...</td>\n",
       "      <td>I've realized that you're seeking guidance on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm on it! I'm here to guide you through the p...</td>\n",
       "      <td>instruction: how do i retrieve my profile pin ...</td>\n",
       "      <td>I'm on the same page, your concern about retri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For sure! I'm here to assist you in retrieving...</td>\n",
       "      <td>:</td>\n",
       "      <td>I'll take care of it! I'm here to assist you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oh no! I understand the frustration and urgenc...</td>\n",
       "      <td>instruction: i cannot rettrieve my damn user p...</td>\n",
       "      <td>I'm sorry to hear that you're having trouble r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unquestionably! I understand your need for inf...</td>\n",
       "      <td>Ich hoffe, dass ich Informationen über meine A...</td>\n",
       "      <td>I'm on it! I'm here to provide you with all th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indeed! I'm here to lend you the expertise you...</td>\n",
       "      <td>Instructions: Instruction instruction instruct...</td>\n",
       "      <td>I'm on it! I'm here to assist you in recoverin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oh no! I understand the frustration of not bei...</td>\n",
       "      <td>instruction: I can't remember my account passw...</td>\n",
       "      <td>I'm sorry to hear that you're having trouble r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I see your confusion and uncertainty about rec...</td>\n",
       "      <td>: I don't know what to do to recover my profil...</td>\n",
       "      <td>I've grasped that you're unsure about the step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Assuredly! I understand the importance of rega...</td>\n",
       "      <td>Ich benötige Hilfe bei der Resetting my accoun...</td>\n",
       "      <td>I'm on the same page, your need for assistance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I'll do my best! I understand the frustration ...</td>\n",
       "      <td>instruction: problem with my PIN reset response:</td>\n",
       "      <td>I'm sorry to hear that you're experiencing dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oh no! I'm so sorry to hear that someone stole...</td>\n",
       "      <td>: a someone stole my user profile PIN, how can...</td>\n",
       "      <td>I'm on it! I'm here to guide you through the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thanks for dropping us a line for support with...</td>\n",
       "      <td>Ich benötige Unterstützung bei der Sign-up-Rea...</td>\n",
       "      <td>We appreciate your proactive approach in seeki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We appreciate your initiative in seeking our a...</td>\n",
       "      <td>: can you help me to report errors with regist...</td>\n",
       "      <td>We appreciate you reaching out to us for assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>We understand that you may be unsure about how...</td>\n",
       "      <td>Instruction: ik do not know how i can notify o...</td>\n",
       "      <td>We understand that you're unsure about how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>We appreciate your inquiry to us regarding the...</td>\n",
       "      <td>Instruction: Instruction: I want assistance to...</td>\n",
       "      <td>We appreciate you reaching out to us for assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>We're here to help to us to report a problem y...</td>\n",
       "      <td>Instructions: notify of problem with signup re...</td>\n",
       "      <td>We appreciate you reaching out to us to report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thank you for your message to us for assistanc...</td>\n",
       "      <td>instruction: I want assistance to report a pro...</td>\n",
       "      <td>We appreciate you reaching out to us for assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Grateful you reached out to us for assistance ...</td>\n",
       "      <td>Instruction:</td>\n",
       "      <td>We appreciate you reaching out to us for assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We appreciate your reaching out to us regardin...</td>\n",
       "      <td>instruction: I cannot create a user, help to i...</td>\n",
       "      <td>We apologize for the inconvenience you're expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>We understand that you require assistance with...</td>\n",
       "      <td>support with my online registration response: ...</td>\n",
       "      <td>We appreciate your inquiry to us for support w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thank you for your message to us to seek assis...</td>\n",
       "      <td>instruction: assistance reporting problems wit...</td>\n",
       "      <td>We appreciate you reaching out to us for assis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Thank you for bringing this to our attention. ...</td>\n",
       "      <td>Ich versuche, zu melden, signup problems respo...</td>\n",
       "      <td>We appreciate you reaching out to us to report...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                human  \\\n",
       "0   Absolutely! I understand the importance of rec...   \n",
       "1   Assuredly! I understand that you are looking f...   \n",
       "2   Unquestionably! I understand the urgency of re...   \n",
       "3   Sure! I'm here to assist you with resetting yo...   \n",
       "4   I'm on it! I'm here to guide you through the p...   \n",
       "5   For sure! I'm here to assist you in retrieving...   \n",
       "6   Oh no! I understand the frustration and urgenc...   \n",
       "7   Unquestionably! I understand your need for inf...   \n",
       "8   Indeed! I'm here to lend you the expertise you...   \n",
       "9   Oh no! I understand the frustration of not bei...   \n",
       "10  I see your confusion and uncertainty about rec...   \n",
       "11  Assuredly! I understand the importance of rega...   \n",
       "12  I'll do my best! I understand the frustration ...   \n",
       "13  Oh no! I'm so sorry to hear that someone stole...   \n",
       "14  Thanks for dropping us a line for support with...   \n",
       "15  We appreciate your initiative in seeking our a...   \n",
       "16  We understand that you may be unsure about how...   \n",
       "17  We appreciate your inquiry to us regarding the...   \n",
       "18  We're here to help to us to report a problem y...   \n",
       "19  Thank you for your message to us for assistanc...   \n",
       "20  Grateful you reached out to us for assistance ...   \n",
       "21  We appreciate your reaching out to us regardin...   \n",
       "22  We understand that you require assistance with...   \n",
       "23  Thank you for your message to us to seek assis...   \n",
       "24  Thank you for bringing this to our attention. ...   \n",
       "\n",
       "                                                 base  \\\n",
       "0                                                   :   \n",
       "1                                                   :   \n",
       "2         I have got to recover my user pwd response:   \n",
       "3   instruction: what do do ot do to reset my user...   \n",
       "4   instruction: how do i retrieve my profile pin ...   \n",
       "5                                                   :   \n",
       "6   instruction: i cannot rettrieve my damn user p...   \n",
       "7   Ich hoffe, dass ich Informationen über meine A...   \n",
       "8   Instructions: Instruction instruction instruct...   \n",
       "9   instruction: I can't remember my account passw...   \n",
       "10  : I don't know what to do to recover my profil...   \n",
       "11  Ich benötige Hilfe bei der Resetting my accoun...   \n",
       "12   instruction: problem with my PIN reset response:   \n",
       "13  : a someone stole my user profile PIN, how can...   \n",
       "14  Ich benötige Unterstützung bei der Sign-up-Rea...   \n",
       "15  : can you help me to report errors with regist...   \n",
       "16  Instruction: ik do not know how i can notify o...   \n",
       "17  Instruction: Instruction: I want assistance to...   \n",
       "18  Instructions: notify of problem with signup re...   \n",
       "19  instruction: I want assistance to report a pro...   \n",
       "20                                       Instruction:   \n",
       "21  instruction: I cannot create a user, help to i...   \n",
       "22  support with my online registration response: ...   \n",
       "23  instruction: assistance reporting problems wit...   \n",
       "24  Ich versuche, zu melden, signup problems respo...   \n",
       "\n",
       "                                            finetuned  \n",
       "0   I'm on the same page, your frustration and urg...  \n",
       "1   I'm on the same page, your need to restore the...  \n",
       "2   I'll get right on it! I'm here to assist you i...  \n",
       "3   I've realized that you're seeking guidance on ...  \n",
       "4   I'm on the same page, your concern about retri...  \n",
       "5   I'll take care of it! I'm here to assist you i...  \n",
       "6   I'm sorry to hear that you're having trouble r...  \n",
       "7   I'm on it! I'm here to provide you with all th...  \n",
       "8   I'm on it! I'm here to assist you in recoverin...  \n",
       "9   I'm sorry to hear that you're having trouble r...  \n",
       "10  I've grasped that you're unsure about the step...  \n",
       "11  I'm on the same page, your need for assistance...  \n",
       "12  I'm sorry to hear that you're experiencing dif...  \n",
       "13  I'm on it! I'm here to guide you through the p...  \n",
       "14  We appreciate your proactive approach in seeki...  \n",
       "15  We appreciate you reaching out to us for assis...  \n",
       "16  We understand that you're unsure about how to ...  \n",
       "17  We appreciate you reaching out to us for assis...  \n",
       "18  We appreciate you reaching out to us to report...  \n",
       "19  We appreciate you reaching out to us for assis...  \n",
       "20  We appreciate you reaching out to us for assis...  \n",
       "21  We apologize for the inconvenience you're expe...  \n",
       "22  We appreciate your inquiry to us for support w...  \n",
       "23  We appreciate you reaching out to us for assis...  \n",
       "24  We appreciate you reaching out to us to report...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_responses = list(zip(responses, base_model_responses, finetuned_model_responses))\n",
    "df = pd.DataFrame(zipped_responses, columns=['human','base','finetuned'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base\n",
      " {'rouge1': 0.06125879176286796, 'rouge2': 0.017930397475075, 'rougeL': 0.05169171787061669, 'rougeLsum': 0.05397238667865421}\n",
      "Fine-tuned\n",
      " {'rouge1': 0.5363634333479866, 'rouge2': 0.27311047339567807, 'rougeL': 0.369923933719136, 'rougeLsum': 0.41543613109721367}\n"
     ]
    }
   ],
   "source": [
    "responses = dataset['test'][0:25]['response']\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=base_model_responses,\n",
    "    references=responses,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('Base\\n',base_model_results)\n",
    "\n",
    "finetuned_model_results = rouge.compute(\n",
    "    predictions=finetuned_model_responses,\n",
    "    references=responses,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('Fine-tuned\\n',finetuned_model_results)\n",
    "\n",
    "# peft_model_results = rouge.compute(\n",
    "#     predictions=peft_model_responses,\n",
    "#     references=response,\n",
    "#     use_aggregator=True,\n",
    "#     use_stemmer=True,\n",
    "# )\n",
    "# print('\\PEFT\\n',peft_model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mforge39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
