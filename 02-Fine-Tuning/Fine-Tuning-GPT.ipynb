{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Check up environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"        \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Let's load data from `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a9a49bba2c4d1d8b44ab00ab0fc4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Bad_Practices', 'Good_Practices'],\n",
       "        num_rows: 6712\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bad_Practices': '<table alt=header>Title</table>',\n",
       " 'Good_Practices': \"<table alt='header'>Title</table>\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bad_Practices</th>\n",
       "      <th>Good_Practices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;table alt=header&gt;Title&lt;/table&gt;</td>\n",
       "      <td>&lt;table alt='header'&gt;Title&lt;/table&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tr&gt;Content</td>\n",
       "      <td>&lt;tr&gt;Content&lt;/tr&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;h2 src='description'&gt;Content</td>\n",
       "      <td>&lt;h2 src='description'&gt;Content&lt;/h2&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;table&gt;Link</td>\n",
       "      <td>&lt;table&gt;Link&lt;/table&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;img src='description'&gt;</td>\n",
       "      <td>&lt;img src='description' alt=''&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bad_Practices                      Good_Practices\n",
       "0  <table alt=header>Title</table>   <table alt='header'>Title</table>\n",
       "1                      <tr>Content                    <tr>Content</tr>\n",
       "2    <h2 src='description'>Content  <h2 src='description'>Content</h2>\n",
       "3                      <table>Link                 <table>Link</table>\n",
       "4          <img src='description'>      <img src='description' alt=''>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('./data.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Define model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Param = 768\n",
      "Total Params = 124439808\n",
      "% of trainable params = 0.0006171658509791337\n"
     ]
    }
   ],
   "source": [
    "def get_num_trainable_params(model):\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    for _ , params in model.named_parameters():\n",
    "        total_params += params.numel()\n",
    "\n",
    "    if params.requires_grad:\n",
    "        total_trainable_params += params.numel()\n",
    "\n",
    "    return f\"Trainable Param = {total_trainable_params}\\nTotal Params = {total_params}\\n% of trainable params = {100*(total_trainable_params/total_params)}\"\n",
    "\n",
    "print(get_num_trainable_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad_token for the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data = dataset[\"train\"].select([i for i in range(len(dataset[\"train\"])) if i % 10 != 0])  # Use 90% of the data for training\n",
    "val_data = dataset[\"train\"].select([i for i in range(len(dataset[\"train\"])) if i % 10 == 0])  # Use 10% of the data for validation\n",
    "\n",
    "# Tokenize the input and target sequences\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['Bad_Practices'], return_tensors='pt', padding='max_length', max_length=512, truncation=True)\n",
    "    labels = tokenizer(examples['Good_Practices'], return_tensors='pt', padding='max_length', max_length=512, truncation=True)\n",
    "    return {'input_ids': inputs['input_ids'], 'labels': labels['input_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tokenization to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = train_data.map(tokenize_function, batched=True)\n",
    "tokenized_val_data = val_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'labels'],\n",
       "    num_rows: 6040\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Bad_Practices', 'Good_Practices', 'input_ids', 'labels'],\n",
       "    num_rows: 672\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "It is now time to fine-tune. We first of all define and set the training argruments and trainer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./gpt2-v1',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=0.5,\n",
    "    per_device_train_batch_size=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    logging_dir='./gpt2-log',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce8b14d237a4c1c87d17f3da419eadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1858, 'grad_norm': 0.6013973355293274, 'learning_rate': 4.668874172185431e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3b3fc05f254c7f9494bcef3574a7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021580364555120468, 'eval_runtime': 45.8685, 'eval_samples_per_second': 14.651, 'eval_steps_per_second': 1.831, 'epoch': 0.03}\n",
      "{'loss': 0.0249, 'grad_norm': 0.5122058987617493, 'learning_rate': 4.337748344370861e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1cad956aee447bac9c27063335b499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019640089944005013, 'eval_runtime': 45.0156, 'eval_samples_per_second': 14.928, 'eval_steps_per_second': 1.866, 'epoch': 0.07}\n",
      "{'loss': 0.0225, 'grad_norm': 0.5484597086906433, 'learning_rate': 4.006622516556292e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c896d1b94b2d406d907aba1a9fbae5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018777277320623398, 'eval_runtime': 44.9996, 'eval_samples_per_second': 14.933, 'eval_steps_per_second': 1.867, 'epoch': 0.1}\n",
      "{'loss': 0.022, 'grad_norm': 0.4539085328578949, 'learning_rate': 3.675496688741722e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bc9f31994142c2bd6aeffbf0435247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018603304401040077, 'eval_runtime': 45.0172, 'eval_samples_per_second': 14.928, 'eval_steps_per_second': 1.866, 'epoch': 0.13}\n",
      "{'loss': 0.0201, 'grad_norm': 0.47286444902420044, 'learning_rate': 3.3443708609271526e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8b519aefb44166b39a341e555530b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017403988167643547, 'eval_runtime': 44.9919, 'eval_samples_per_second': 14.936, 'eval_steps_per_second': 1.867, 'epoch': 0.17}\n",
      "{'loss': 0.0195, 'grad_norm': 0.7612916231155396, 'learning_rate': 3.0132450331125826e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceac59643894edba6d317e6b9eeb706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017642980441451073, 'eval_runtime': 44.9974, 'eval_samples_per_second': 14.934, 'eval_steps_per_second': 1.867, 'epoch': 0.2}\n",
      "{'loss': 0.0193, 'grad_norm': 0.4788755774497986, 'learning_rate': 2.6821192052980134e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3106c494ce5046b4aa6e5a2d1adc05ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016922488808631897, 'eval_runtime': 44.9803, 'eval_samples_per_second': 14.94, 'eval_steps_per_second': 1.867, 'epoch': 0.23}\n",
      "{'loss': 0.0195, 'grad_norm': 0.6407566666603088, 'learning_rate': 2.3509933774834437e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82b949aeaa042cfb12fabfdbdd48c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01767270267009735, 'eval_runtime': 45.0077, 'eval_samples_per_second': 14.931, 'eval_steps_per_second': 1.866, 'epoch': 0.26}\n",
      "{'loss': 0.0191, 'grad_norm': 0.4587347209453583, 'learning_rate': 2.0198675496688745e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b87b6c92b194a3cae1013f438788d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017101578414440155, 'eval_runtime': 44.9872, 'eval_samples_per_second': 14.938, 'eval_steps_per_second': 1.867, 'epoch': 0.3}\n",
      "{'loss': 0.0193, 'grad_norm': 0.6490234136581421, 'learning_rate': 1.688741721854305e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e35594049f547df8f920043264feb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017166651785373688, 'eval_runtime': 45.0401, 'eval_samples_per_second': 14.92, 'eval_steps_per_second': 1.865, 'epoch': 0.33}\n",
      "{'loss': 0.0183, 'grad_norm': 0.49436986446380615, 'learning_rate': 1.3576158940397351e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d808f332ad74557b8f780e142c78187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016910996288061142, 'eval_runtime': 46.6092, 'eval_samples_per_second': 14.418, 'eval_steps_per_second': 1.802, 'epoch': 0.36}\n",
      "{'loss': 0.018, 'grad_norm': 0.46442288160324097, 'learning_rate': 1.0264900662251655e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a157932068e4843a98a9cdf464f5206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01680365391075611, 'eval_runtime': 45.2884, 'eval_samples_per_second': 14.838, 'eval_steps_per_second': 1.855, 'epoch': 0.4}\n",
      "{'loss': 0.0179, 'grad_norm': 0.5831215381622314, 'learning_rate': 6.95364238410596e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf6a07222dc430fbf53668d68361328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01646830514073372, 'eval_runtime': 45.0171, 'eval_samples_per_second': 14.928, 'eval_steps_per_second': 1.866, 'epoch': 0.43}\n",
      "{'loss': 0.0185, 'grad_norm': 0.5309569835662842, 'learning_rate': 3.642384105960265e-06, 'epoch': 0.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db74e41de4f4a158303509f457fbeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016424572095274925, 'eval_runtime': 45.0727, 'eval_samples_per_second': 14.909, 'eval_steps_per_second': 1.864, 'epoch': 0.46}\n",
      "{'loss': 0.0175, 'grad_norm': 0.6122424602508545, 'learning_rate': 3.3112582781456954e-07, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f66f24efcd94ae798b4fa6b904dc104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01641058549284935, 'eval_runtime': 45.0827, 'eval_samples_per_second': 14.906, 'eval_steps_per_second': 1.863, 'epoch': 0.5}\n",
      "{'train_runtime': 2740.826, 'train_samples_per_second': 1.102, 'train_steps_per_second': 0.551, 'train_loss': 0.03072101294204889, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1510, training_loss=0.03072101294204889, metrics={'train_runtime': 2740.826, 'train_samples_per_second': 1.102, 'train_steps_per_second': 0.551, 'total_flos': 789101936640000.0, 'train_loss': 0.03072101294204889, 'epoch': 0.5})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6b22ddd8e04be79ef1956af367bf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.02\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f'Perplexity: {math.exp(eval_results[\"eval_loss\"]):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mforge39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
